{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linda Fister's story with IBM beyond mirrors the onset and boom of computers. Exeter Township, PA —\n",
      "The big metal box with blinking lights transfixed 12-year-old Linda Fister.\n",
      "It was the first computer she had seen, and Fister stood staring in wonder at the state-of-the-art display at the Museum of Science and Industry in Chicago.\n",
      "“It piqued my curiosity,” she said. “I thought, 'This is the future.' ”\n",
      "There and then, she decided it would be her future.\n",
      "A retired computer programmer, Fister, now 75, of Exeter Township was the only woman in her class when she started programming close to 60 years ago. In recognition of Day of the Programmer, an international professional day celebrated Sept. 13, she recently reflected on what it was like to be a woman in the early days of programming.\n",
      "A few years after that decisive museum trip, Fister, who grew up in a suburb of the Windy City, walked into the Chicago office of International Business Machines, or IBM, to ask for a job. A precocious teenager, Fister was ushered into the office of a manager. Impressed by Fister's interest in what were called “business machines,” the man handed her his card and instructed her to return after graduating high school.\n",
      "She did and landed an internship with IBM.\n",
      "In exchange for her work, Fister received training as a keypuncher, punching holes into the stiff paper cards that issued commands when fed into the large mainframe computers. She also learned the jobs of card sorting and board wiring, all of which were considered women's work, she said. TV show nailed it\n",
      "Fister's classes were filled with other young women, all “dressed like Audrey Hepburn” with high heels and gloves.\n",
      "“Did you ever watch 'Mad Men?' ” she asked. “That's exactly how it was.”\n",
      "“Mad Men,” an American period television drama, gave an accurate depiction of the professional workplace in the 1960s, she said, right down to the afternoon office cocktails.\n",
      "There was sexism in the workplace, too, she said, particularly in the amount women were paid and the jobs available to them.\n",
      "Fister worked in the “clean room,” a temperature controlled laboratory where floor-to-ceiling computers stored data on reel-to-reel magnetic tapes. Bored by sorting the punched cards, she began studying the repetitive patterns of ones and zeroes in the code.\n",
      "There were some mistakes, she realized, flagging those cards.\n",
      "When one of the coders, as the programmers were called, questioned Fister about “her errors,” she told him: “These are not my mistakes. They are yours.”\n",
      "And she proved it, earning herself a seat in IBM's next programming class.\n",
      "Fister was the only woman in her coding course, unlike in her earlier classes.\n",
      "“I was uncomfortable and felt out of place,” she said. “But I was always professional. No flirtation.”\n",
      "Some of her male counterparts were skeptical, but she earned their respect by keeping up to pace in Formula Translation, better known as Fortran, and RPG, an IBM proprietary language for business applications.\n",
      "Programming requires an analytical mind, Fister said, and she had that.\n",
      "“I still analyze everything,” she said.\n",
      "About a year into her training, the coder she corrected took a job at another company and asked her to work for him. Fister embarked on a new adventure but continued taking classes at IBM. No glamour\n",
      "There were times her boss would call after midnight.\n",
      "“Get ready,” he would say. “We have run time.”\n",
      "A taxi would arrive to pick her up, and she would be ready and waiting, dressed in her heels with her white gloves on. After running programs through the night without sleep, they were expected to begin as usual in the morning.\n",
      "“Everyone thinks it was so glamorous,” she said. “It wasn't. It was just work.”\n",
      "Women in the 1960s were expected to marry and have children, Fister said, noting many of her friends married right after high school.\n",
      "“I wanted that, too,” she said. “I wanted children and a life outside the city.”\n",
      "After three years in programming, Fister married and moved with her new husband to his native Berks County.\n",
      "She was happy as a stay-at-home mother, rearing their two daughters. But when the marriage ended, Fister decided to go back to work. By then, it was 1984 and computers had changed tremendously.\n",
      "She enrolled in a computer programming course offered by an Allentown-area business school. Though the computers were different, she said, one thing was the same: Fister was the only woman in the class.\n",
      "She was studying newer computer languages — Beginner's All-purpose Symbolic Instruction Code, or BASIC, and Common Business-Oriented Language, or COBOL — when her mother fell ill and died three months later.\n",
      "Realizing Fister had been distracted and was in mourning, the instructor arranged for a private tutor and helped her snag a programming job with a Reading-area nonprofit.\n",
      "There was no software specifically for nonprofits at the time, Fister said, so she rewrote business programs to suit their needs. She also was responsible for data entry and used the programs she wrote for record keeping, payroll, accounting and filing various state and federal reports.\n",
      "Fister said she often wasn't “taken seriously” by management and coworkers, who didn't understand what her work entailed, and she was lonely, working solo in the computer room. So, she joined an organization for professional programmers, but once again, she was the only woman in the group.\n",
      "Before her retirement in 1995, she dabbled in Microsoft Windows, the graphical user interface that would revolutionize personal computing.\n",
      "“By then, I had learned six computer languages and was burnt out,” she said. “But the desire to work with computers is still there. It is almost like it is in my DNA.”\n",
      "https://www.readingeagle.com/news/article/exeter-township-woman-began-career-in-computer-programming-in-1962\n",
      "Someday, a new class of semiconductor companies will assemble their products Lego-style, mixing and matching dice from multiple companies. It’s a huge change that’s still a long way off.\n",
      "More than 146 people from 80 companies signed up for an event last week at IBM’s Almaden Research Center to take some small steps in this direction. It was the third major face-to-face this year for the Open Domain-Specific Architecture (ODSA) group, following others hosted by Samsung and Intel.\n",
      "In a sign of growing interest, a similar event a year ago drew fewer than half as many people from fewer than half as many companies. “We don’t know if we have the right solution, but we are reasonably confident we have the right problem,” said Bapi Vinnakota, a Netronome engineer who leads ODSA.\n",
      "The problem is that chiplets lack open interoperable interfaces that would enable anyone to assemble them into products. In an effort to create such interfaces, ODSA has started work on physical and link layer specs. It also is designing a board-level proof-of-concept and curating a catalog of existing chiplets, often using proprietary interfaces.\n",
      "The overall picture from the event was one of an ambitious effort still in its early stages and hungry for engineering and financial resources. A core set of companies, including Globalfoundries, Intel, NXP, Xilinx, and about 20 others are actively participating, but the group needs more help—especially from test vendors and other foundries.\n",
      "A PROPRIETARY PAST\n",
      "The chiplet concept has been around since the multi-chip modules of the 1970’s. Today, the idea is gaining commercial popularity as a way to lower design costs at a time when leading-edge process technologies are become a prohibitively expensive way to design large integrated chips.\n",
      "For example, AMD built its Ryzen and Epyc x86 processors out of chiplets connected on its Infinity Fabric. Intel is using its EMIB and Foveros packaging techniques to link dice in current and future products.\n",
      "Startup zGlue, an active ODSA member, is already offering tools and services for designing modules with chiplets, mainly aimed at the Internet of Things. Its users have several projects in the works, including some for the military, but none have shipped to end users as of yet.\n",
      "Former Marvell CEO Sehat Sutardja, who attended last week’s ODSA event, was an early promoter of chiplets with his MoChi concept sketched out in a 2015 keynote at ISSCC. At the ODSA event, he informally promoted the latest version of his concept for a final-level cache as an enabler for chiplets.\n",
      "For its part, IBM described in a talk its Open Memory Interface (OMI) that was announced last month. OMI is a subset of IBM’s OpenCAPI interface aimed at making its server processors more flexible by enabling a market for external memory controllers created by third parties.\n",
      "IBM is working to get Jedec to create a standard DDR5 DIMM based on OMI. “Open source chiplets could help every company focus on its areas of differentiation,” said Steve Fields, a chief engineer for Power servers.\n",
      "A WORK-IN-PROGRESS\n",
      "Plowing its own path, ODSA has an initial list of six publicly available chiplets as a starting point for an online chiplet exchange it wants to create. The short-term goal is to get the industry to start shipping and using chiplets with whatever interfaces vendors want to use, even though they will mainly be proprietary ones.\n",
      "Toward its long-term goal of creating open interconnects for chiplets, it aims to release at the end of the month a version 0.7 spec for its open physical-layer interface. It is simply called a bunch of wires (BoW). In addition, about a dozen engineers are working to modify existing PIPE interfaces to marry various existing PHYs and link-layer protocols.\n",
      "Meanwhile, its proof-of-concept aims to demonstrate the process of how chiplet design would work using existing chips placed on a small printed circuit board with existing interconnects. ODSA is close to a deal to get a limited number of the boards made, although the effort still lacks adequate funding. The boards would give early supporters a vehicle to run and test applications software.\n",
      "The boards will come in two flavors. One will be a smart network-interface card based on a Netronome network processor combined with an Achronix FPGA and multi-core ARM CPU from NXP. Another will substitute the Netronome part for a second FPGA to handle computational storage.\n",
      "“We’d love to have people stress our architecture with their software and use cases,” said Quinn Jacobson of Achronix, who leads the team.\n",
      "The group’s BoW is a 16-wire source-synchronous parallel interface similar to the AIB interface Intel uses in its EMIB package and recently released as open source. It aims to support as much as a Tbit/second of data per millimeter of die edge space at an efficiency of less than a picojoule/bit. Traces could extend up to 50mm, and latencies aim to be as low as 5ns.\n",
      "“There are multiple proprietary parallel interfaces being built…and an open standard is a great way to converge these designs,” said Mark Kuemerle, who leads the BoW group and is a fellow at Avera Semiconductor, the former Globalfoundries ASIC group now being acquired by Marvell.\n",
      "The BoW design will allow a variety of bump pitches “but will insist on a bump order to avoid a spaghetti of package routing,” he added.\n",
      "NEEDS AND HISTORY\n",
      "The biggest needs for the BoW effort are partners to prototype IP with it and foundries to donate shuttle space for them. Kuemerle also called for help defining the initialization and calibration of the interface, as well as robust test solutions– which he sees as ODSA’s most critical need, overall, at the moment.\n",
      "“We need input from the test community. We have good ideas that need to be well developed,” he said.\n",
      "David Kehlet, an Intel engineer overseeing ODSA’s link-layer protocols, called for more work on versions of AXI to accommodate variations among chiplets that will range from RF front ends to memory controllers. “I’ve seen good thoughts on AXI modifications, but nothing available to use,” he said, encouraging open source efforts.\n",
      "Vinnakota of Netronome and a handful of others published a white paper on the topic of chiplets that sparked the formation of ODSA about year ago. The Open Compute Project (OCP) formed by Facebook agreed to host the project as part of its even broader ambitions to define open versions of everything it needs to build its warehouse-sized data centers.\n",
      "“We want to get to the point of a completely open system including processors and accelerators,” said Bill Carter, chief technologist of OCP, noting a vision articulated by Aaron Sullivan, now part of Facebook’s semiconductor group for open systems from silicon to racks. Related\n"
     ]
    }
   ],
   "source": [
    "#1.Pick a random news article (preferably with many entity mentions) from your Webhose dataset \n",
    "import json\n",
    "\n",
    "#read data from json file\n",
    "json_data=open(\"IBM_english.json\").readlines()\n",
    "#print(json_data)\n",
    "\n",
    "#Output: print the number of articles, titles and publish dates of the first 100 articles.\n",
    "feeds_read_from_file = []\n",
    "for line in json_data:\n",
    "    feeds_read_from_file.append(json.loads(line))\n",
    "#print(len(feeds_read_from_file))\n",
    "\n",
    "#Pick a random news article from your Webhose dataset \n",
    "article = feeds_read_from_file[9]['text']\n",
    "article_url = feeds_read_from_file[9]['url']\n",
    "\n",
    "print(article)\n",
    "print(article_url)\n",
    "\n",
    "#len(article['text'])\n",
    "\n",
    "#Pick a random test article from your Webhose dataset \n",
    "test = feeds_read_from_file[3]['text']\n",
    "#len(article['text'])\n",
    "print(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of sentences: 56\n",
      "sentence: 0\n",
      "Linda Fister's story with IBM beyond mirrors the onset and boom of computers.\n",
      "sentence: 1\n",
      "Exeter Township, PA —\n",
      "The big metal box with blinking lights transfixed 12-year-old Linda Fister.\n",
      "sentence: 2\n",
      "It was the first computer she had seen, and Fister stood staring in wonder at the state-of-the-art display at the Museum of Science and Industry in Chicago.\n",
      "sentence: 3\n",
      "“It piqued my curiosity,” she said.\n",
      "sentence: 4\n",
      "“I thought, 'This is the future.'\n",
      "sentence: 5\n",
      "”\n",
      "There and then, she decided it would be her future.\n",
      "sentence: 6\n",
      "A retired computer programmer, Fister, now 75, of Exeter Township was the only woman in her class when she started programming close to 60 years ago.\n",
      "sentence: 7\n",
      "In recognition of Day of the Programmer, an international professional day celebrated Sept. 13, she recently reflected on what it was like to be a woman in the early days of programming.\n",
      "sentence: 8\n",
      "A few years after that decisive museum trip, Fister, who grew up in a suburb of the Windy City, walked into the Chicago office of International Business Machines, or IBM, to ask for a job.\n",
      "sentence: 9\n",
      "A precocious teenager, Fister was ushered into the office of a manager.\n",
      "sentence: 10\n",
      "Impressed by Fister's interest in what were called “business machines,” the man handed her his card and instructed her to return after graduating high school.\n",
      "sentence: 11\n",
      "She did and landed an internship with IBM.\n",
      "sentence: 12\n",
      "In exchange for her work, Fister received training as a keypuncher, punching holes into the stiff paper cards that issued commands when fed into the large mainframe computers.\n",
      "sentence: 13\n",
      "She also learned the jobs of card sorting and board wiring, all of which were considered women's work, she said.\n",
      "sentence: 14\n",
      "TV show nailed it\n",
      "Fister's classes were filled with other young women, all “dressed like Audrey Hepburn” with high heels and gloves.\n",
      "sentence: 15\n",
      "“Did you ever watch 'Mad Men?'\n",
      "sentence: 16\n",
      "” she asked.\n",
      "sentence: 17\n",
      "“That's exactly how it was.”\n",
      "“Mad Men,” an American period television drama, gave an accurate depiction of the professional workplace in the 1960s, she said, right down to the afternoon office cocktails.\n",
      "sentence: 18\n",
      "There was sexism in the workplace, too, she said, particularly in the amount women were paid and the jobs available to them.\n",
      "sentence: 19\n",
      "Fister worked in the “clean room,” a temperature controlled laboratory where floor-to-ceiling computers stored data on reel-to-reel magnetic tapes.\n",
      "sentence: 20\n",
      "Bored by sorting the punched cards, she began studying the repetitive patterns of ones and zeroes in the code.\n",
      "sentence: 21\n",
      "There were some mistakes, she realized, flagging those cards.\n",
      "sentence: 22\n",
      "When one of the coders, as the programmers were called, questioned Fister about “her errors,” she told him: “These are not my mistakes.\n",
      "sentence: 23\n",
      "They are yours.”\n",
      "And she proved it, earning herself a seat in IBM's next programming class.\n",
      "sentence: 24\n",
      "Fister was the only woman in her coding course, unlike in her earlier classes.\n",
      "sentence: 25\n",
      "“I was uncomfortable and felt out of place,” she said.\n",
      "sentence: 26\n",
      "“But I was always professional.\n",
      "sentence: 27\n",
      "No flirtation.”\n",
      "Some of her male counterparts were skeptical, but she earned their respect by keeping up to pace in Formula Translation, better known as Fortran, and RPG, an IBM proprietary language for business applications.\n",
      "sentence: 28\n",
      "Programming requires an analytical mind, Fister said, and she had that.\n",
      "sentence: 29\n",
      "“I still analyze everything,” she said.\n",
      "sentence: 30\n",
      "About a year into her training, the coder she corrected took a job at another company and asked her to work for him.\n",
      "sentence: 31\n",
      "Fister embarked on a new adventure but continued taking classes at IBM.\n",
      "sentence: 32\n",
      "No glamour\n",
      "There were times her boss would call after midnight.\n",
      "sentence: 33\n",
      "“Get ready,” he would say.\n",
      "sentence: 34\n",
      "“We have run time.”\n",
      "A taxi would arrive to pick her up, and she would be ready and waiting, dressed in her heels with her white gloves on.\n",
      "sentence: 35\n",
      "After running programs through the night without sleep, they were expected to begin as usual in the morning.\n",
      "sentence: 36\n",
      "“Everyone thinks it was so glamorous,” she said.\n",
      "sentence: 37\n",
      "“It wasn't.\n",
      "sentence: 38\n",
      "It was just work.”\n",
      "Women in the 1960s were expected to marry and have children, Fister said, noting many of her friends married right after high school.\n",
      "sentence: 39\n",
      "“I wanted that, too,” she said.\n",
      "sentence: 40\n",
      "“I wanted children and a life outside the city.”\n",
      "After three years in programming, Fister married and moved with her new husband to his native Berks County.\n",
      "sentence: 41\n",
      "She was happy as a stay-at-home mother, rearing their two daughters.\n",
      "sentence: 42\n",
      "But when the marriage ended, Fister decided to go back to work.\n",
      "sentence: 43\n",
      "By then, it was 1984 and computers had changed tremendously.\n",
      "sentence: 44\n",
      "She enrolled in a computer programming course offered by an Allentown-area business school.\n",
      "sentence: 45\n",
      "Though the computers were different, she said, one thing was the same: Fister was the only woman in the class.\n",
      "sentence: 46\n",
      "She was studying newer computer languages — Beginner's All-purpose Symbolic Instruction Code, or BASIC, and Common Business-Oriented Language, or COBOL — when her mother fell ill and died three months later.\n",
      "sentence: 47\n",
      "Realizing Fister had been distracted and was in mourning, the instructor arranged for a private tutor and helped her snag a programming job with a Reading-area nonprofit.\n",
      "sentence: 48\n",
      "There was no software specifically for nonprofits at the time, Fister said, so she rewrote business programs to suit their needs.\n",
      "sentence: 49\n",
      "She also was responsible for data entry and used the programs she wrote for record keeping, payroll, accounting and filing various state and federal reports.\n",
      "sentence: 50\n",
      "Fister said she often wasn't “taken seriously” by management and coworkers, who didn't understand what her work entailed, and she was lonely, working solo in the computer room.\n",
      "sentence: 51\n",
      "So, she joined an organization for professional programmers, but once again, she was the only woman in the group.\n",
      "sentence: 52\n",
      "Before her retirement in 1995, she dabbled in Microsoft Windows, the graphical user interface that would revolutionize personal computing.\n",
      "sentence: 53\n",
      "“By then, I had learned six computer languages and was burnt out,” she said.\n",
      "sentence: 54\n",
      "“But the desire to work with computers is still there.\n",
      "sentence: 55\n",
      "It is almost like it is in my DNA.”\n"
     ]
    }
   ],
   "source": [
    "#Tokenize sentences \n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize, ngrams, pos_tag, RegexpParser\n",
    "from collections import Counter\n",
    "\n",
    "#from nltk import tokenize\n",
    "# tokenize sentences\n",
    "sentences = sent_tokenize(article)\n",
    "print('# of sentences:',len(sentences))\n",
    "\n",
    "count=0\n",
    "for line in sentences:\n",
    "    print(\"sentence:\",count)\n",
    "    print(line)\n",
    "    count=count+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM\n",
      "International Business Machine IBM\n",
      "IBM\n",
      "IBM\n",
      "IBM\n",
      "IBM\n",
      "Allentown-area business school\n",
      "organization\n"
     ]
    }
   ],
   "source": [
    "print(sentences[0][26:29])\n",
    "print(sentences[8][130:160],sentences[8][166:169])\n",
    "print(sentences[11][38:41])\n",
    "print(sentences[23][62:65])\n",
    "print(sentences[27][174:177])\n",
    "print(sentences[31][67:70])\n",
    "print(sentences[44][60:90])\n",
    "print(sentences[51][18:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update TRAIN_DATA with annotations of entities (PERSON, LOCATION, or ORGANIZATION) from each sentence in the selected news article\n",
    "TRAIN_DATA = [\n",
    "    (sentences[0], {\"entities\": [(26, 29, \"ORG\")]}),\n",
    "    (sentences[8], {\"entities\": [(130, 160, \"ORG\"), (166, 169, \"ORG\")]}),\n",
    "    (sentences[11], {\"entities\": [(38, 41, \"ORG\")]}),\n",
    "    (sentences[23], {\"entities\": [(62, 65, \"ORG\")]}),\n",
    "    (sentences[27], {\"entities\": [(174, 177, \"ORG\")]}),\n",
    "    (sentences[31], {\"entities\": [(67, 70, \"ORG\")]}),\n",
    "    (sentences[44], {\"entities\": [(60, 90, \"ORG\")]}),\n",
    "    (sentences[51], {\"entities\": [(18, 30, \"ORG\")]}),\n",
    "   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /anaconda3/lib/python3.7/site-packages (2.1.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /anaconda3/lib/python3.7/site-packages (from spacy) (2.0.2)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (1.16.4)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /anaconda3/lib/python3.7/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.1.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /anaconda3/lib/python3.7/site-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from spacy) (0.2.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /anaconda3/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.32.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install spacy \n",
    "\n",
    "!pip install spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /anaconda3/lib/python3.7/site-packages (2.1.0)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run spaCy_NER function to generate trained_nlp model\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the built-in pipeline components and add them to the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe(\"ner\")\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add labels\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 36.32638852158561}\n",
      "Losses {'ner': 19.351716697216034}\n",
      "Losses {'ner': 37.23130480153486}\n",
      "Losses {'ner': 14.838703060289845}\n",
      "Losses {'ner': 19.930521067144582}\n",
      "Losses {'ner': 17.210292600793764}\n",
      "Losses {'ner': 12.752193732536398}\n",
      "Losses {'ner': 13.312805344403387}\n",
      "Losses {'ner': 7.127047104476333}\n",
      "Losses {'ner': 15.518727780610789}\n",
      "Losses {'ner': 6.645637699930376}\n",
      "Losses {'ner': 11.328733414165981}\n",
      "Losses {'ner': 12.729191844220964}\n",
      "Losses {'ner': 11.747025308748562}\n",
      "Losses {'ner': 8.21453882926653}\n",
      "Losses {'ner': 5.004280650723331}\n",
      "Losses {'ner': 9.140535384089162}\n",
      "Losses {'ner': 5.666354907825735}\n",
      "Losses {'ner': 8.4677728091483}\n",
      "Losses {'ner': 14.66655692178756}\n",
      "Losses {'ner': 6.927038345364053}\n",
      "Losses {'ner': 8.627055278320768}\n",
      "Losses {'ner': 6.749617352536006}\n",
      "Losses {'ner': 7.688319371201942}\n",
      "Losses {'ner': 3.0982062307591}\n",
      "Losses {'ner': 5.901205892844587}\n",
      "Losses {'ner': 5.75887910999927}\n",
      "Losses {'ner': 3.441872582085125}\n",
      "Losses {'ner': 3.910064725679831}\n",
      "Losses {'ner': 7.745269612280232}\n",
      "Losses {'ner': 8.98566547761311}\n",
      "Losses {'ner': 3.074643688063759}\n",
      "Losses {'ner': 3.1640063339577864}\n",
      "Losses {'ner': 4.91727305707218}\n",
      "Losses {'ner': 5.023973682068515}\n",
      "Losses {'ner': 2.8236143942058334}\n",
      "Losses {'ner': 2.5592594457254876}\n",
      "Losses {'ner': 6.758372869069717}\n",
      "Losses {'ner': 3.6249287320025587}\n",
      "Losses {'ner': 1.9902330055499533}\n",
      "Losses {'ner': 7.40857737456686}\n",
      "Losses {'ner': 0.8966256477875674}\n",
      "Losses {'ner': 3.8266784228815283}\n",
      "Losses {'ner': 4.181811477450323}\n",
      "Losses {'ner': 5.468782478458575}\n",
      "Losses {'ner': 5.5827614662821645}\n",
      "Losses {'ner': 3.785022066401768}\n",
      "Losses {'ner': 5.689724979934839}\n",
      "Losses {'ner': 2.8116310412381735}\n",
      "Losses {'ner': 1.2640799124842275}\n",
      "Losses {'ner': 1.5578536209060987}\n",
      "Losses {'ner': 0.6589258385078729}\n",
      "Losses {'ner': 2.6696643405874063}\n",
      "Losses {'ner': 5.660839428646466}\n",
      "Losses {'ner': 2.7351732185741753}\n",
      "Losses {'ner': 2.706475470928225}\n",
      "Losses {'ner': 2.8290085956080464}\n",
      "Losses {'ner': 3.056211485544857}\n",
      "Losses {'ner': 3.8618258960174336}\n",
      "Losses {'ner': 2.5929912330300837}\n",
      "Losses {'ner': 1.265195118572905}\n",
      "Losses {'ner': 1.5305445119393486}\n",
      "Losses {'ner': 0.010139319400302327}\n",
      "Losses {'ner': 4.8437241019434465}\n",
      "Losses {'ner': 2.70878598479013}\n",
      "Losses {'ner': 0.4052878807149058}\n",
      "Losses {'ner': 4.422849446593592}\n",
      "Losses {'ner': 1.1590915278616534}\n",
      "Losses {'ner': 4.066405176169383}\n",
      "Losses {'ner': 3.129689393229122}\n",
      "Losses {'ner': 3.5042170658882807}\n",
      "Losses {'ner': 0.7694870999872627}\n",
      "Losses {'ner': 0.018472576030981402}\n",
      "Losses {'ner': 7.452192363081457}\n",
      "Losses {'ner': 0.05566728766518697}\n",
      "Losses {'ner': 1.3645827927787793}\n",
      "Losses {'ner': 0.320274336697271}\n",
      "Losses {'ner': 0.6361385855785651}\n",
      "Losses {'ner': 0.8481238046630952}\n",
      "Losses {'ner': 0.260716224130924}\n",
      "Losses {'ner': 3.856848972243884}\n",
      "Losses {'ner': 3.2814790791225215}\n",
      "Losses {'ner': 0.4361982836468939}\n",
      "Losses {'ner': 5.811882183205373}\n",
      "Losses {'ner': 2.0892741245571447}\n",
      "Losses {'ner': 3.1444079909587748}\n",
      "Losses {'ner': 5.1724455831309095}\n",
      "Losses {'ner': 6.623418672705606}\n",
      "Losses {'ner': 0.19561387894725094}\n",
      "Losses {'ner': 2.9505336614147666}\n",
      "Losses {'ner': 0.05804297460630265}\n",
      "Losses {'ner': 0.00873028014748674}\n",
      "Losses {'ner': 0.8331469658339782}\n",
      "Losses {'ner': 6.360604914261305}\n",
      "Losses {'ner': 0.5944265695787245}\n",
      "Losses {'ner': 0.15137279486327043}\n",
      "Losses {'ner': 0.016225709983931653}\n",
      "Losses {'ner': 2.068388727954797}\n",
      "Losses {'ner': 8.723254688718912}\n",
      "Losses {'ner': 0.00634569895069448}\n"
     ]
    }
   ],
   "source": [
    "#Train NER\n",
    "n_iter=100\n",
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    # reset and initialize the weights randomly – but only if we're\n",
    "    # training a new model\n",
    "    #if model is None:\n",
    "    nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                losses=losses,\n",
    "            )\n",
    "        print(\"Losses\", losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('IBM', 'ORG')]\n",
      "Tokens [('No', '', 2), ('flirtation', '', 2), ('.', '', 2), ('”', '', 2), ('\\n', '', 2), ('Some', '', 2), ('of', '', 2), ('her', '', 2), ('male', '', 2), ('counterparts', '', 2), ('were', '', 2), ('skeptical', '', 2), (',', '', 2), ('but', '', 2), ('she', '', 2), ('earned', '', 2), ('their', '', 2), ('respect', '', 2), ('by', '', 2), ('keeping', '', 2), ('up', '', 2), ('to', '', 2), ('pace', '', 2), ('in', '', 2), ('Formula', '', 2), ('Translation', '', 2), (',', '', 2), ('better', '', 2), ('known', '', 2), ('as', '', 2), ('Fortran', '', 2), (',', '', 2), ('and', '', 2), ('RPG', '', 2), (',', '', 2), ('an', '', 2), ('IBM', 'ORG', 3), ('proprietary', '', 2), ('language', '', 2), ('for', '', 2), ('business', '', 2), ('applications', '', 2), ('.', '', 2)]\n",
      "Entities [('IBM', 'ORG')]\n",
      "Tokens [('She', '', 2), ('did', '', 2), ('and', '', 2), ('landed', '', 2), ('an', '', 2), ('internship', '', 2), ('with', '', 2), ('IBM', 'ORG', 3), ('.', '', 2)]\n",
      "Entities [('International Business Machines, or', 'ORG'), ('IBM', 'ORG')]\n",
      "Tokens [('A', '', 2), ('few', '', 2), ('years', '', 2), ('after', '', 2), ('that', '', 2), ('decisive', '', 2), ('museum', '', 2), ('trip', '', 2), (',', '', 2), ('Fister', '', 2), (',', '', 2), ('who', '', 2), ('grew', '', 2), ('up', '', 2), ('in', '', 2), ('a', '', 2), ('suburb', '', 2), ('of', '', 2), ('the', '', 2), ('Windy', '', 2), ('City', '', 2), (',', '', 2), ('walked', '', 2), ('into', '', 2), ('the', '', 2), ('Chicago', '', 2), ('office', '', 2), ('of', '', 2), ('International', 'ORG', 3), ('Business', 'ORG', 1), ('Machines', 'ORG', 1), (',', 'ORG', 1), ('or', 'ORG', 1), ('IBM', 'ORG', 3), (',', '', 2), ('to', '', 2), ('ask', '', 2), ('for', '', 2), ('a', '', 2), ('job', '', 2), ('.', '', 2)]\n",
      "Entities [('IBM', 'ORG')]\n",
      "Tokens [('Fister', '', 2), ('embarked', '', 2), ('on', '', 2), ('a', '', 2), ('new', '', 2), ('adventure', '', 2), ('but', '', 2), ('continued', '', 2), ('taking', '', 2), ('classes', '', 2), ('at', '', 2), ('IBM', 'ORG', 3), ('.', '', 2)]\n",
      "Entities [('organization', 'ORG')]\n",
      "Tokens [('So', '', 2), (',', '', 2), ('she', '', 2), ('joined', '', 2), ('an', '', 2), ('organization', 'ORG', 3), ('for', '', 2), ('professional', '', 2), ('programmers', '', 2), (',', '', 2), ('but', '', 2), ('once', '', 2), ('again', '', 2), (',', '', 2), ('she', '', 2), ('was', '', 2), ('the', '', 2), ('only', '', 2), ('woman', '', 2), ('in', '', 2), ('the', '', 2), ('group', '', 2), ('.', '', 2)]\n",
      "Entities [('IBM', 'ORG')]\n",
      "Tokens [('Linda', '', 2), ('Fister', '', 2), (\"'s\", '', 2), ('story', '', 2), ('with', '', 2), ('IBM', 'ORG', 3), ('beyond', '', 2), ('mirrors', '', 2), ('the', '', 2), ('onset', '', 2), ('and', '', 2), ('boom', '', 2), ('of', '', 2), ('computers', '', 2), ('.', '', 2)]\n",
      "Entities [('IBM', 'ORG')]\n",
      "Tokens [('They', '', 2), ('are', '', 2), ('yours', '', 2), ('.', '', 2), ('”', '', 2), ('\\n', '', 2), ('And', '', 2), ('she', '', 2), ('proved', '', 2), ('it', '', 2), (',', '', 2), ('earning', '', 2), ('herself', '', 2), ('a', '', 2), ('seat', '', 2), ('in', '', 2), ('IBM', 'ORG', 3), (\"'s\", '', 2), ('next', '', 2), ('programming', '', 2), ('class', '', 2), ('.', '', 2)]\n",
      "Entities [('Allentown-area business school', 'ORG')]\n",
      "Tokens [('She', '', 2), ('enrolled', '', 2), ('in', '', 2), ('a', '', 2), ('computer', '', 2), ('programming', '', 2), ('course', '', 2), ('offered', '', 2), ('by', '', 2), ('an', '', 2), ('Allentown', 'ORG', 3), ('-', 'ORG', 1), ('area', 'ORG', 1), ('business', 'ORG', 1), ('school', 'ORG', 1), ('.', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "# test the trained model \n",
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print(\"Tokens\", [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statring iteration 0\n",
      "{'ner': 107.25856900215149}\n",
      "Statring iteration 1\n",
      "{'ner': 18.939542730544872}\n",
      "Statring iteration 2\n",
      "{'ner': 12.61003939968441}\n",
      "Statring iteration 3\n",
      "{'ner': 7.810625788726654}\n",
      "Statring iteration 4\n",
      "{'ner': 3.2564568093882533}\n",
      "Statring iteration 5\n",
      "{'ner': 1.3145751149162712}\n",
      "Statring iteration 6\n",
      "{'ner': 1.6307507148000429}\n",
      "Statring iteration 7\n",
      "{'ner': 9.620695947077055}\n",
      "Statring iteration 8\n",
      "{'ner': 4.605250749938947}\n",
      "Statring iteration 9\n",
      "{'ner': 4.501363718152714}\n",
      "Statring iteration 10\n",
      "{'ner': 2.7076242212399593}\n",
      "Statring iteration 11\n",
      "{'ner': 2.1860470380960244}\n",
      "Statring iteration 12\n",
      "{'ner': 4.678292948178114}\n",
      "Statring iteration 13\n",
      "{'ner': 2.232514249616217}\n",
      "Statring iteration 14\n",
      "{'ner': 1.967812652715275}\n",
      "Statring iteration 15\n",
      "{'ner': 2.0556907426367887}\n",
      "Statring iteration 16\n",
      "{'ner': 3.429128123671626}\n",
      "Statring iteration 17\n",
      "{'ner': 2.1033418445967227}\n",
      "Statring iteration 18\n",
      "{'ner': 0.4892249814454363}\n",
      "Statring iteration 19\n",
      "{'ner': 0.15688536596215294}\n"
     ]
    }
   ],
   "source": [
    "def train_spacy(data,iterations):\n",
    "    TRAIN_DATA = data\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    # create the built-in pipeline components and add them to the pipeline\n",
    "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "    if 'ner' not in nlp.pipe_names:\n",
    "        ner = nlp.create_pipe('ner')\n",
    "        nlp.add_pipe(ner, last=True)\n",
    "       \n",
    "\n",
    "    # add labels\n",
    "    for _, annotations in TRAIN_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])\n",
    "\n",
    "    # get names of other pipes to disable them during training\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(\"Statring iteration \" + str(itn))\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                nlp.update(\n",
    "                    [text],  # batch of texts\n",
    "                    [annotations],  # batch of annotations\n",
    "                    drop=0.2,  # dropout - make it harder to memorise data\n",
    "                    sgd=optimizer,  # callable to update weights\n",
    "                    losses=losses)\n",
    "            print(losses)\n",
    "    return nlp\n",
    "\n",
    "\n",
    "prdnlp = train_spacy(TRAIN_DATA, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Model Name: IBM\n",
      "Enter your testing text: Someday, a new class of semiconductor companies will assemble their products Lego-style, mixing and matching dice from multiple companies. It’s a huge change that’s still a long way off. More than 146 people from 80 companies signed up for an event last week at IBM’s Almaden Research Center to take some small steps in this direction. It was the third major face-to-face this year for the Open Domain-Specific Architecture (ODSA) group, following others hosted by Samsung and Intel. In a sign of growing interest, a similar event a year ago drew fewer than half as many people from fewer than half as many companies. “We don’t know if we have the right solution, but we are reasonably confident we have the right problem,” said Bapi Vinnakota, a Netronome engineer who leads ODSA. The problem is that chiplets lack open interoperable interfaces that would enable anyone to assemble them into products. In an effort to create such interfaces, ODSA has started work on physical and link layer specs. It also is designing a board-level proof-of-concept and curating a catalog of existing chiplets, often using proprietary interfaces. The overall picture from the event was one of an ambitious effort still in its early stages and hungry for engineering and financial resources. A core set of companies, including Globalfoundries, Intel, NXP, Xilinx, and about 20 others are actively participating, but the group needs more help—especially from test vendors and other foundries. A PROPRIETARY PAST The chiplet concept has been around since the multi-chip modules of the 1970’s. Today, the idea is gaining commercial popularity as a way to lower design costs at a time when leading-edge process technologies are become a prohibitively expensive way to design large integrated chips. For example, AMD built its Ryzen and Epyc x86 processors out of chiplets connected on its Infinity Fabric. Intel is using its EMIB and Foveros packaging techniques to link dice in current and future products. Startup zGlue, an active ODSA member, is already offering tools and services for designing modules with chiplets, mainly aimed at the Internet of Things. Its users have several projects in the works, including some for the military, but none have shipped to end users as of yet. Former Marvell CEO Sehat Sutardja, who attended last week’s ODSA event, was an early promoter of chiplets with his MoChi concept sketched out in a 2015 keynote at ISSCC. At the ODSA event, he informally promoted the latest version of his concept for a final-level cache as an enabler for chiplets. For its part, IBM described in a talk its Open Memory Interface (OMI) that was announced last month. OMI is a subset of IBM’s OpenCAPI interface aimed at making its server processors more flexible by enabling a market for external memory controllers created by third parties. IBM is working to get Jedec to create a standard DDR5 DIMM based on OMI. “Open source chiplets could help every company focus on its areas of differentiation,” said Steve Fields, a chief engineer for Power servers. A WORK-IN-PROGRESS Plowing its own path, ODSA has an initial list of six publicly available chiplets as a starting point for an online chiplet exchange it wants to create. The short-term goal is to get the industry to start shipping and using chiplets with whatever interfaces vendors want to use, even though they will mainly be proprietary ones. Toward its long-term goal of creating open interconnects for chiplets, it aims to release at the end of the month a version 0.7 spec for its open physical-layer interface. It is simply called a bunch of wires (BoW). In addition, about a dozen engineers are working to modify existing PIPE interfaces to marry various existing PHYs and link-layer protocols. Meanwhile, its proof-of-concept aims to demonstrate the process of how chiplet design would work using existing chips placed on a small printed circuit board with existing interconnects. ODSA is close to a deal to get a limited number of the boards made, although the effort still lacks adequate funding. The boards would give early supporters a vehicle to run and test applications software. The boards will come in two flavors. One will be a smart network-interface card based on a Netronome network processor combined with an Achronix FPGA and multi-core ARM CPU from NXP. Another will substitute the Netronome part for a second FPGA to handle computational storage. “We’d love to have people stress our architecture with their software and use cases,” said Quinn Jacobson of Achronix, who leads the team. The group’s BoW is a 16-wire source-synchronous parallel interface similar to the AIB interface Intel uses in its EMIB package and recently released as open source. It aims to support as much as a Tbit/second of data per millimeter of die edge space at an efficiency of less than a picojoule/bit. Traces could extend up to 50mm, and latencies aim to be as low as 5ns. “There are multiple proprietary parallel interfaces being built…and an open standard is a great way to converge these designs,” said Mark Kuemerle, who leads the BoW group and is a fellow at Avera Semiconductor, the former Globalfoundries ASIC group now being acquired by Marvell. The BoW design will allow a variety of bump pitches “but will insist on a bump order to avoid a spaghetti of package routing,” he added. NEEDS AND HISTORY The biggest needs for the BoW effort are partners to prototype IP with it and foundries to donate shuttle space for them. Kuemerle also called for help defining the initialization and calibration of the interface, as well as robust test solutions– which he sees as ODSA’s most critical need, overall, at the moment. “We need input from the test community. We have good ideas that need to be well developed,” he said. David Kehlet, an Intel engineer overseeing ODSA’s link-layer protocols, called for more work on versions of AXI to accommodate variations among chiplets that will range from RF front ends to memory controllers. “I’ve seen good thoughts on AXI modifications, but nothing available to use,” he said, encouraging open source efforts. Vinnakota of Netronome and a handful of others published a white paper on the topic of chiplets that sparked the formation of ODSA about year ago. The Open Compute Project (OCP) formed by Facebook agreed to host the project as part of its even broader ambitions to define open versions of everything it needs to build its warehouse-sized data centers. “We want to get to the point of a completely open system including processors and accelerators,” said Bill Carter, chief technologist of OCP, noting a vision articulated by Aaron Sullivan, now part of Facebook’s semiconductor group for open systems from silicon to racks. Related\n",
      "IBM 262 265 ORG\n",
      "ISSCC 2430 2435 ORG\n",
      "IBM 2685 2688 ORG\n",
      "IBM 2841 2844 ORG\n",
      "IN 3063 3065 ORG\n",
      "-PROGRESS Plowing its 3065 3086 ORG\n",
      "of-concept aims to 3782 3800 ORG\n",
      "- 4218 4219 ORG\n",
      "Achronix FPGA and 4290 4307 ORG\n",
      "synchronous 4606 4617 ORG\n",
      "Intel 5808 5813 ORG\n",
      "- 6453 6454 ORG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save our trained Model\n",
    "modelfile = input(\"Enter your Model Name: \")\n",
    "prdnlp.to_disk(modelfile)\n",
    "\n",
    "#use trained_nlp to test entity recognition on another random news article from Webhose and print results to output\n",
    "\n",
    "test_text = input(\"Enter your testing text: \")\n",
    "doc = prdnlp(test_text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm-watson>=3.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/30/6e444a420b533b53e6b8ab4318ce1a9b19662067515aca0351403bdb615c/ibm-watson-4.0.1.tar.gz (297kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 3.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3.0,>=2.0 in /anaconda3/lib/python3.7/site-packages (from ibm-watson>=3.4.0) (2.22.0)\n",
      "Requirement already satisfied, skipping upgrade: python_dateutil>=2.5.3 in /anaconda3/lib/python3.7/site-packages (from ibm-watson>=3.4.0) (2.8.0)\n",
      "Collecting websocket-client==0.48.0 (from ibm-watson>=3.4.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/a1/72ef9aa26cfe1a75cee09fc1957e4723add9de098c15719416a1ee89386b/websocket_client-0.48.0-py2.py3-none-any.whl (198kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 19.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ibm_cloud_sdk_core==1.0.0 (from ibm-watson>=3.4.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/43/a13a5956c69b7becce7a0df6d2340c1e32322df3b39f57a3b33dc4645a34/ibm-cloud-sdk-core-1.0.0.tar.gz\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson>=3.4.0) (1.24.2)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson>=3.4.0) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson>=3.4.0) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests<3.0,>=2.0->ibm-watson>=3.4.0) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /anaconda3/lib/python3.7/site-packages (from python_dateutil>=2.5.3->ibm-watson>=3.4.0) (1.12.0)\n",
      "Collecting PyJWT>=1.7.1 (from ibm_cloud_sdk_core==1.0.0->ibm-watson>=3.4.0)\n",
      "  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n",
      "  Building wheel for ibm-watson (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/rissacao/Library/Caches/pip/wheels/40/73/8a/809e738908cd1b0d34a383219c49ede9f9fba487584ad3377f\n",
      "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/rissacao/Library/Caches/pip/wheels/12/e5/b5/90c69cc81edf5b95cbec373c83c3530266fdae8266037380df\n",
      "Successfully built ibm-watson ibm-cloud-sdk-core\n",
      "Installing collected packages: websocket-client, PyJWT, ibm-cloud-sdk-core, ibm-watson\n",
      "Successfully installed PyJWT-1.7.1 ibm-cloud-sdk-core-1.0.0 ibm-watson-4.0.1 websocket-client-0.48.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#3. Choose  one  of  the  Information Extraction  services  below,  setup  a free  account, \n",
    "\n",
    "pip install --upgrade \"ibm-watson>=3.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"usage\": {\n",
      "    \"text_units\": 1,\n",
      "    \"text_characters\": 5729,\n",
      "    \"features\": 1\n",
      "  },\n",
      "  \"retrieved_url\": \"https://www.readingeagle.com/news/article/exeter-township-woman-began-career-in-computer-programming-in-1962\",\n",
      "  \"language\": \"en\",\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"type\": \"Person\",\n",
      "      \"text\": \"Fister\",\n",
      "      \"relevance\": 0.978348,\n",
      "      \"count\": 19,\n",
      "      \"confidence\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Exeter Township\",\n",
      "      \"relevance\": 0.358766,\n",
      "      \"count\": 2,\n",
      "      \"confidence\": 0.999045\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"IBM\",\n",
      "      \"relevance\": 0.226842,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"SoftwareLicense\",\n",
      "          \"Organization\",\n",
      "          \"OperatingSystemDeveloper\",\n",
      "          \"ProcessorManufacturer\",\n",
      "          \"SoftwareDeveloper\",\n",
      "          \"CompanyFounder\",\n",
      "          \"ProgrammingLanguageDesigner\",\n",
      "          \"ProgrammingLanguageDeveloper\"\n",
      "        ],\n",
      "        \"name\": \"IBM\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/IBM\"\n",
      "      },\n",
      "      \"count\": 5,\n",
      "      \"confidence\": 1\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Person\",\n",
      "      \"text\": \"Michelle N. Lynch\",\n",
      "      \"relevance\": 0.197925,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.984641\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Person\",\n",
      "      \"text\": \"Linda Fister\",\n",
      "      \"relevance\": 0.192264,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.991408\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Facility\",\n",
      "      \"text\": \"Chicago office of International Business Machines\",\n",
      "      \"relevance\": 0.167249,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.091088\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Facility\",\n",
      "      \"text\": \"Museum of Science and Industry\",\n",
      "      \"relevance\": 0.117813,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"Location\",\n",
      "          \"TouristAttraction\",\n",
      "          \"Building\",\n",
      "          \"Museum\"\n",
      "        ],\n",
      "        \"name\": \"Oregon_Museum_of_Science_and_Industry\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Oregon_Museum_of_Science_and_Industry\"\n",
      "      },\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.413618\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Quantity\",\n",
      "      \"text\": \"12-year\",\n",
      "      \"relevance\": 0.109842,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Windy City\",\n",
      "      \"relevance\": 0.094272,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.477724\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Quantity\",\n",
      "      \"text\": \"60 years\",\n",
      "      \"relevance\": 0.084558,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Person\",\n",
      "      \"text\": \"Audrey Hepburn\",\n",
      "      \"relevance\": 0.082628,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"Actor\",\n",
      "          \"MusicalArtist\",\n",
      "          \"AwardNominee\",\n",
      "          \"AwardWinner\",\n",
      "          \"Celebrity\",\n",
      "          \"FilmActor\",\n",
      "          \"TVActor\"\n",
      "        ],\n",
      "        \"name\": \"Audrey_Hepburn\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Audrey_Hepburn\"\n",
      "      },\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.990989\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"TelevisionShow\",\n",
      "      \"text\": \"Mad Men\",\n",
      "      \"relevance\": 0.074329,\n",
      "      \"disambiguation\": {\n",
      "        \"name\": \"Mad_Men\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Mad_Men\"\n",
      "      },\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.728948\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"PA\",\n",
      "      \"relevance\": 0.072445,\n",
      "      \"disambiguation\": {\n",
      "        \"name\": \"Palestinian_National_Authority\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Palestinian_National_Authority\"\n",
      "      },\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.999561\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Chicago\",\n",
      "      \"relevance\": 0.062293,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.986576\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Berks County\",\n",
      "      \"relevance\": 0.036197,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.973195\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Location\",\n",
      "      \"text\": \"Allentown\",\n",
      "      \"relevance\": 0.026547,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.931542\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Quantity\",\n",
      "      \"text\": \"three years\",\n",
      "      \"relevance\": 0.023196,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Quantity\",\n",
      "      \"text\": \"three months\",\n",
      "      \"relevance\": 0.015666,\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.8\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"Company\",\n",
      "      \"text\": \"Microsoft\",\n",
      "      \"relevance\": 0.002963,\n",
      "      \"disambiguation\": {\n",
      "        \"subtype\": [\n",
      "          \"Organization\",\n",
      "          \"OperatingSystemDeveloper\",\n",
      "          \"ProcessorManufacturer\",\n",
      "          \"SoftwareDeveloper\",\n",
      "          \"VentureFundedCompany\",\n",
      "          \"VideoGameDeveloper\",\n",
      "          \"VideoGamePublisher\",\n",
      "          \"ProgrammingLanguageDesigner\"\n",
      "        ],\n",
      "        \"name\": \"Microsoft\",\n",
      "        \"dbpedia_resource\": \"http://dbpedia.org/resource/Microsoft\"\n",
      "      },\n",
      "      \"count\": 1,\n",
      "      \"confidence\": 0.991851\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#obtain API key from (https://cloud.ibm.com/services/natural-language-understanding/crn%3Av1%3Abluemix%3Apublic%3Anatural-language-understanding%3Aus-south%3Aa%2Fd233267034ac49f0b942af45cf16b07f%3Aa60ba095-298a-419b-a77c-7e21faba55d1%3A%3A?paneId=credentials&new=true) \n",
    "#write Python API calls to extract Company or Organization entities from  the article chosen in Step 1:\n",
    "\n",
    "import json\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions, KeywordsOptions\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "authenticator = IAMAuthenticator('FuXAct3C-cU0bI-XYf6agqyHh7PL6abtMa2YtN7-30hg')\n",
    "service = NaturalLanguageUnderstandingV1(\n",
    "    version='2019-07-12',\n",
    "    authenticator=authenticator)\n",
    "service.set_service_url('https://gateway.watsonplatform.net/natural-language-understanding/api')\n",
    "\n",
    "response = service.analyze(\n",
    "    url='https://www.readingeagle.com/news/article/exeter-township-woman-began-career-in-computer-programming-in-1962',\n",
    "    features=Features(entities=EntitiesOptions())).get_result()\n",
    "\n",
    "\n",
    "print(json.dumps(response, indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/21/f05c186f4ddb01d15d0ddc36ef4b7e3cedbeb6412274a41f26b55a650ee5/pyspark-2.4.4.tar.gz (215.7MB)\n",
      "\u001b[K     |████████████████████████████████| 215.7MB 107kB/s  eta 0:00:01   |██▍                             | 15.8MB 2.9MB/s eta 0:01:10     |█████████                       | 60.0MB 23.2MB/s eta 0:00:07     |██████████████▌                 | 98.1MB 10.0MB/s eta 0:00:12     |████████████████                | 107.8MB 8.9MB/s eta 0:00:13     |████████████████████▉           | 140.4MB 21.6MB/s eta 0:00:04     |██████████████████████▉         | 153.6MB 21.6MB/s eta 0:00:03     |███████████████████████▍        | 157.5MB 21.6MB/s eta 0:00:03     |████████████████████████▍       | 164.5MB 21.6MB/s eta 0:00:03     |█████████████████████████▎      | 170.5MB 20.7MB/s eta 0:00:03     |████████████████████████████    | 189.1MB 20.7MB/s eta 0:00:02     |████████████████████████████▌   | 192.2MB 20.7MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting py4j==0.10.7 (from pyspark)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/53/c737818eb9a7dc32a7cd4f1396e787bd94200c3997c72c1dbe028587bd76/py4j-0.10.7-py2.py3-none-any.whl (197kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 27.8MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/rissacao/Library/Caches/pip/wheels/ab/09/4d/0d184230058e654eb1b04467dbc1292f00eaa186544604b471\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.7 pyspark-2.4.4\n"
     ]
    }
   ],
   "source": [
    "#4.Download Crunchbase Open Data Map CSV file (366MB) and store it in a directory on your computer\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Apache Spark Version 2.4.4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "sc = SparkContext() \n",
    "config = sc.getConf() \n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "print(\"Using Apache Spark Version\", sc.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/rissacao/Downloads/5430'"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687755"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Crunchbase Open Data Map into notebook \n",
    "#by modifying the path .csv(\".../...\") to the file on your computer \n",
    "#where you stored the downloaded CSV file from Step 4.\n",
    "\n",
    "\n",
    "df = sqlContext.read.option(\"header\", \"true\").option(\"delimiter\", \",\") \\\n",
    "                    .option(\"inferSchema\", \"true\") \\\n",
    "                    .csv(\"/Users/rissacao/Downloads/5430/cb_odm_092419.csv\")\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#match_df = df[df['name'].contains(\"Disney\")]\n",
    "match_df = df.filter(df.homepage_domain.like('%columbia.edu%'))\n",
    "#match_df = df.filter(df.short_description.like('%electric car%'))\n",
    "match_df['crunchbase_uuid','name','homepage_domain','stock_symbol'].show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+----------------------+---------------+------------+\n",
      "|crunchbase_uuid                     |name                  |homepage_domain|stock_symbol|\n",
      "+------------------------------------+----------------------+---------------+------------+\n",
      "|fc5fbe7a-562d-d577-b05e-46797caa134c|IBM                   |ibm.com        |swx:IBM     |\n",
      "|fc5fbe7a-562d-d577-b05e-46797caa134c|IBM                   |ibm.com        |lse:IBM     |\n",
      "|fc5fbe7a-562d-d577-b05e-46797caa134c|IBM                   |ibm.com        |nyse:IBM    |\n",
      "|fc5fbe7a-562d-d577-b05e-46797caa134c|IBM                   |ibm.com        |fra:IBM     |\n",
      "|3efd1ca9-5434-5feb-942c-5f3347a8b81a|IBM Global Services   |ibm.com        |:           |\n",
      "|097740ba-25f9-d4d6-fb7e-e76ca8f7960e|IBM Security Services |ibm.com        |:           |\n",
      "|b16a7278-55aa-9fbf-2c33-5af6bde83b30|IBM Research          |ibm.com        |:           |\n",
      "|edbd4d6e-f235-f70d-4f4c-48e521078f9f|IBM United Kingdom Ltd|ibm.com        |:           |\n",
      "|bfae874f-14ec-7105-23cb-d7941923e023|IBM Cloud             |ibm.com        |:           |\n",
      "|091b0e30-383c-2172-3091-903f5f77f124|IBM Watson Health     |ibm.com        |:           |\n",
      "+------------------------------------+----------------------+---------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#find matches of Company or Organization entities identified in Step 3 using rlike function and print results\n",
    "\n",
    "#organization 1: IBM\n",
    "match_df = df[df['name'].rlike(\"IBM\")& df['homepage_domain'].rlike(\"ibm.com\")]\n",
    "match_df['crunchbase_uuid','name','homepage_domain','stock_symbol'].show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----+---------------+------------+\n",
      "|crunchbase_uuid|name|homepage_domain|stock_symbol|\n",
      "+---------------+----+---------------+------------+\n",
      "+---------------+----+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#organization 2: Microsoft\n",
    "match_df = df[df['name'].rlike(\"Microsoft\")& df['homepage_domain'].rlike(\"Microsoft.com\")]\n",
    "match_df['crunchbase_uuid','name','homepage_domain','stock_symbol'].show(10, truncate=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
